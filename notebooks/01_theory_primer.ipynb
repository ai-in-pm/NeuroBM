{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Boltzmann Machines for Cognitive Modeling: Theory Primer\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Educational/Research Purpose Only - No Clinical Applications**\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides a comprehensive introduction to using Boltzmann machines for modeling cognitive patterns and brain dynamics. All results are hypothetical and for research/educational purposes only.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## ‚ö†Ô∏è Important Disclaimers\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Educational Purpose Only**: This is a theoretical exploration with significant uncertainty\\n\",\n",
    "    \"- **No Clinical Value**: No diagnostic, predictive, or treatment applications\\n\",\n",
    "    \"- **Synthetic Data**: All examples use artificially generated data\\n\",\n",
    "    \"- **Simplified Models**: Real brain dynamics are vastly more complex\\n\",\n",
    "    \"- **Validation Required**: All hypotheses require proper clinical validation\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Learning Objectives\\n\",\n",
    "    \"\\n\",\n",
    "    \"By the end of this notebook, you will understand:\\n\",\n",
    "    \"1. Basic principles of Boltzmann machines and energy-based models\\n\",\n",
    "    \"2. How to model cognitive features as probabilistic patterns\\n\",\n",
    "    \"3. The connection between statistical mechanics and neural computation\\n\",\n",
    "    \"4. Practical implementation of RBMs for cognitive modeling\\n\",\n",
    "    \"5. Interpretation techniques for understanding learned representations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Standard imports\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"sys.path.append(str(Path.cwd().parent))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# NeuroBM imports\\n\",\n",
    "    \"from neurobm.models.rbm import RestrictedBoltzmannMachine\\n\",\n",
    "    \"from neurobm.models.dbm import DeepBoltzmannMachine\\n\",\n",
    "    \"from neurobm.data.synth import SyntheticDataGenerator\\n\",\n",
    "    \"from neurobm.data.loaders import get_data_loader\\n\",\n",
    "    \"from neurobm.data.schema import get_schema\\n\",\n",
    "    \"from neurobm.interpret.saliency import SaliencyAnalyzer\\n\",\n",
    "    \"from neurobm.interpret.traversals import LatentTraverser\\n\",\n",
    "    \"from neurobm.interpret.tiles import FilterVisualizer\\n\",\n",
    "    \"from neurobm.training.loop import TrainingLoop\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style and random seeds for reproducibility\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"np.random.seed(42)\\n\",\n",
    "    \"torch.manual_seed(42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup device\\n\",\n",
    "    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
    "    \"print(f\\\"Using device: {device}\\\")\\n\",\n",
    "    \"print(f\\\"PyTorch version: {torch.__version__}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nüß† Welcome to Cognitive Modeling with Boltzmann Machines!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Theoretical Foundation\\n\",\n",
    "    \"\\n\",\n",
    "    \"### What are Boltzmann Machines?\\n\",\n",
    "    \"\\n\",\n",
    "    \"Boltzmann machines are **energy-based probabilistic models** inspired by statistical mechanics. They model the probability distribution of data through an energy function:\\n\",\n",
    "    \"\\n\",\n",
    "    \"$$P(\\\\mathbf{v}) = \\\\frac{1}{Z} e^{-E(\\\\mathbf{v})}$$\\n\",\n",
    "    \"\\n\",\n",
    "    \"Where:\\n\",\n",
    "    \"- $\\\\mathbf{v}$ is a visible state (our observed data)\\n\",\n",
    "    \"- $E(\\\\mathbf{v})$ is the energy function\\n\",\n",
    "    \"- $Z$ is the partition function (normalization constant)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Why Use Them for Cognitive Modeling?\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Probabilistic Nature**: Cognition involves uncertainty and probabilistic processes\\n\",\n",
    "    \"2. **Distributed Representations**: Multiple cognitive features interact in complex ways\\n\",\n",
    "    \"3. **Energy Landscapes**: Mental states can be viewed as energy configurations\\n\",\n",
    "    \"4. **Emergent Patterns**: Complex behaviors emerge from simple local interactions\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Restricted Boltzmann Machines (RBMs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"RBMs are a tractable subset of Boltzmann machines with:\\n\",\n",
    "    \"- **Visible units** $\\\\mathbf{v}$: Observable cognitive features\\n\",\n",
    "    \"- **Hidden units** $\\\\mathbf{h}$: Latent cognitive factors\\n\",\n",
    "    \"- **No intra-layer connections**: Only visible-hidden connections\\n\",\n",
    "    \"\\n\",\n",
    "    \"Energy function:\\n\",\n",
    "    \"$$E(\\\\mathbf{v}, \\\\mathbf{h}) = -\\\\mathbf{v}^T \\\\mathbf{W} \\\\mathbf{h} - \\\\mathbf{b}^T \\\\mathbf{v} - \\\\mathbf{c}^T \\\\mathbf{h}$$\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Let's visualize the RBM architecture\\n\",\n",
    "    \"from neurobm.interpret.tiles import create_model_architecture_diagram\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create a simple RBM for demonstration\\n\",\n",
    "    \"demo_rbm = RestrictedBoltzmannMachine(\\n\",\n",
    "    \"    n_visible=6,  # 6 cognitive features\\n\",\n",
    "    \"    n_hidden=4,   # 4 latent factors\\n\",\n",
    "    \"    device=device\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize the architecture\\n\",\n",
    "    \"fig = create_model_architecture_diagram(demo_rbm, figsize=(10, 6))\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä RBM Architecture:\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Visible units: {demo_rbm.n_visible} (cognitive features)\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Hidden units: {demo_rbm.n_hidden} (latent factors)\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Parameters: {sum(p.numel() for p in demo_rbm.parameters())} total\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Weight matrix shape: {demo_rbm.W.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Cognitive Feature Modeling\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Representing Cognitive States\\n\",\n",
    "    \"\\n\",\n",
    "    \"In our framework, cognitive states are represented as vectors of features:\\n\",\n",
    "    \"- **Attention span**: Ability to maintain focus\\n\",\n",
    "    \"- **Working memory**: Capacity for temporary information storage\\n\",\n",
    "    \"- **Novelty seeking**: Tendency to explore new experiences\\n\",\n",
    "    \"- **Sleep quality**: Restorative sleep patterns\\n\",\n",
    "    \"- **Stress index**: Overall stress level\\n\",\n",
    "    \"\\n\",\n",
    "    \"Each feature is normalized to [0,1] where:\\n\",\n",
    "    \"- 0 = Low/Poor functioning\\n\",\n",
    "    \"- 1 = High/Optimal functioning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate synthetic cognitive data\\n\",\n",
    "    \"print(\\\"üî¨ Generating Synthetic Cognitive Data...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create data generator for base cognitive features\\n\",\n",
    "    \"generator = SyntheticDataGenerator('base', random_seed=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate sample data\\n\",\n",
    "    \"data = generator.generate_samples(n_samples=1000, method='skewed')\\n\",\n",
    "    \"feature_names = list(generator.schema.features.keys())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Generated {len(data)} samples with {len(feature_names)} features:\\\")\\n\",\n",
    "    \"for i, name in enumerate(feature_names):\\n\",\n",
    "    \"    print(f\\\"  {i+1}. {name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert to DataFrame for analysis\\n\",\n",
    "    \"df = pd.DataFrame(data.numpy(), columns=feature_names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display basic statistics\\n\",\n",
    "    \"print(\\\"\\\\nüìà Data Statistics:\\\")\\n\",\n",
    "    \"print(df.describe().round(3))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize the cognitive feature distributions\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 3, figsize=(15, 10))\\n\",\n",
    "    \"axes = axes.flatten()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, feature in enumerate(feature_names):\\n\",\n",
    "    \"    if i < len(axes):\\n\",\n",
    "    \"        axes[i].hist(df[feature], bins=30, alpha=0.7, density=True, color=sns.color_palette()[i])\\n\",\n",
    "    \"        axes[i].set_title(f'{feature.replace(\\\"_\\\", \\\" \\\").title()}')\\n\",\n",
    "    \"        axes[i].set_xlabel('Value')\\n\",\n",
    "    \"        axes[i].set_ylabel('Density')\\n\",\n",
    "    \"        axes[i].grid(True, alpha=0.3)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add mean line\\n\",\n",
    "    \"        mean_val = df[feature].mean()\\n\",\n",
    "    \"        axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, label=f'Mean: {mean_val:.2f}')\\n\",\n",
    "    \"        axes[i].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Hide unused subplot\\n\",\n",
    "    \"if len(feature_names) < len(axes):\\n\",\n",
    "    \"    axes[-1].set_visible(False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.suptitle('Distribution of Cognitive Features in Synthetic Data', fontsize=16)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüí° Observations:\\\")\\n\",\n",
    "    \"print(\\\"‚Ä¢ Features show realistic skewed distributions\\\")\\n\",\n",
    "    \"print(\\\"‚Ä¢ Most people have moderate-to-good cognitive functioning\\\")\\n\",\n",
    "    \"print(\\\"‚Ä¢ Some features show bimodal patterns (e.g., sleep quality)\\\")\\n\",\n",
    "    \"print(\\\"‚Ä¢ Stress tends to be higher on average (realistic!)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Examine feature correlations\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"correlation_matrix = df.corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create heatmap\\n\",\n",
    "    \"mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\\n\",\n",
    "    \"sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\\n\",\n",
    "    \"            square=True, fmt='.2f', cbar_kws={\\\"shrink\\\": .8})\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title('Cognitive Feature Correlations', fontsize=14)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüîó Key Correlations:\\\")\\n\",\n",
    "    \"# Find strongest correlations\\n\",\n",
    "    \"corr_pairs = []\\n\",\n",
    "    \"for i in range(len(feature_names)):\\n\",\n",
    "    \"    for j in range(i+1, len(feature_names)):\\n\",\n",
    "    \"        corr_val = correlation_matrix.iloc[i, j]\\n\",\n",
    "    \"        corr_pairs.append((feature_names[i], feature_names[j], corr_val))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sort by absolute correlation\\n\",\n",
    "    \"corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for feat1, feat2, corr in corr_pairs[:3]:\\n\",\n",
    "    \"    direction = \\\"positively\\\" if corr > 0 else \\\"negatively\\\"\\n\",\n",
    "    \"    print(f\\\"‚Ä¢ {feat1} and {feat2} are {direction} correlated (r={corr:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Training an RBM on Cognitive Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Now let's train an RBM to learn the underlying patterns in our cognitive data. The RBM will discover latent factors that explain the correlations between cognitive features.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create and configure RBM\\n\",\n",
    "    \"print(\\\"üß† Creating Restricted Boltzmann Machine...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"rbm = RestrictedBoltzmannMachine(\\n\",\n",
    "    \"    n_visible=len(feature_names),\\n\",\n",
    "    \"    n_hidden=8,  # 8 latent cognitive factors\\n\",\n",
    "    \"    visible_type='bernoulli',\\n\",\n",
    "    \"    learning_rate=0.01,\\n\",\n",
    "    \"    momentum=0.9,\\n\",\n",
    "    \"    device=device\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"RBM Configuration:\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Visible units: {rbm.n_visible}\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Hidden units: {rbm.n_hidden}\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Learning rate: {rbm.learning_rate}\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Device: {rbm.device}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create data loader\\n\",\n",
    "    \"data_loader = get_data_loader(\\n\",\n",
    "    \"    regime_name='base',\\n\",\n",
    "    \"    n_samples=1000,\\n\",\n",
    "    \"    batch_size=32,\\n\",\n",
    "    \"    shuffle=True\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Data Loader:\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Batch size: 32\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Total batches: {len(data_loader)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train the RBM\\n\",\n",
    "    \"print(\\\"üöÄ Training RBM...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Simple training loop\\n\",\n",
    "    \"rbm.train()\\n\",\n",
    "    \"training_losses = []\\n\",\n",
    "    \"reconstruction_errors = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"n_epochs = 50\\n\",\n",
    "    \"for epoch in range(n_epochs):\\n\",\n",
    "    \"    epoch_loss = 0\\n\",\n",
    "    \"    epoch_recon_error = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for batch_idx, batch_data in enumerate(data_loader):\\n\",\n",
    "    \"        # Train on batch\\n\",\n",
    "    \"        metrics = rbm.train_batch(batch_data, k=1)\\n\",\n",
    "    \"        epoch_loss += metrics['reconstruction_error']\\n\",\n",
    "    \"        epoch_recon_error += metrics['reconstruction_error']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Average over batches\\n\",\n",
    "    \"    avg_loss = epoch_loss / len(data_loader)\\n\",\n",
    "    \"    avg_recon = epoch_recon_error / len(data_loader)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    training_losses.append(avg_loss)\\n\",\n",
    "    \"    reconstruction_errors.append(avg_recon)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if (epoch + 1) % 10 == 0:\\n\",\n",
    "    \"        print(f\\\"Epoch {epoch+1:2d}/{n_epochs}: Loss = {avg_loss:.4f}, Reconstruction Error = {avg_recon:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Training completed!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training progress\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Training loss\\n\",\n",
    "    \"ax1.plot(training_losses, 'b-', linewidth=2)\\n\",\n",
    "    \"ax1.set_title('Training Loss Over Time')\\n\",\n",
    "    \"ax1.set_xlabel('Epoch')\\n\",\n",
    "    \"ax1.set_ylabel('Loss')\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Reconstruction error\\n\",\n",
    "    \"ax2.plot(reconstruction_errors, 'r-', linewidth=2)\\n\",\n",
    "    \"ax2.set_title('Reconstruction Error Over Time')\\n\",\n",
    "    \"ax2.set_xlabel('Epoch')\\n\",\n",
    "    \"ax2.set_ylabel('Reconstruction Error')\\n\",\n",
    "    \"ax2.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"final_loss = training_losses[-1]\\n\",\n",
    "    \"final_recon = reconstruction_errors[-1]\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Final Training Metrics:\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Final loss: {final_loss:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Final reconstruction error: {final_recon:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"‚Ä¢ Training converged: {'Yes' if final_loss < 0.1 else 'Needs more epochs'}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"version\": \"3.12.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
